from pathlib import Path
from typing import Optional
from fastapi import FastAPI, Request  # type: ignore
from fastapi.responses import Response, HTMLResponse, RedirectResponse  # type: ignore
from fastapi.templating import Jinja2Templates  # type: ignore
from pydantic import BaseModel  # type: ignore
import duckdb  # type: ignore
import pandas as pd  # type: ignore
import matplotlib  # type: ignore
matplotlib.use('Agg')  # ÏÑúÎ≤Ñ ÌôòÍ≤ΩÏóêÏÑú ÌïÑÏöîÌïú Î∞±ÏóîÎìú ÏÑ§Ï†ï
import matplotlib.pyplot as plt  # type: ignore
import matplotlib.font_manager as fm  # type: ignore
import io
import json
from datetime import datetime

# ÌïúÍ∏Ä Ìè∞Ìä∏ ÏÑ§Ï†ï (macOSÏóêÏÑú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Ìè∞Ìä∏ Ïö∞ÏÑ† ÏÇ¨Ïö©)
plt.rcParams['font.family'] = 'Apple SD Gothic Neo'  # macOS Í∏∞Î≥∏ ÌïúÍ∏Ä Ìè∞Ìä∏
plt.rcParams['axes.unicode_minus'] = False  # ÏùåÏàò Í∏∞Ìò∏ Íπ®Ïßê Î∞©ÏßÄ
from src.nl_parse import parse_question
from src.sql_builder import build_sql
from src.process_metrics import (
    build_stable_avg_sql,
    build_overshoot_sql,
    build_dwell_time_sql,
    build_outlier_detection_sql,
    build_trace_compare_sql,
)
from src.chart_templates import get_chart_template, apply_chart_template

DB = Path.home() / "ald_app" / "data_out" / "ald.duckdb"

app = FastAPI(title="ALD NL‚ÜíSQL Stats API")
templates = Jinja2Templates(directory=str(Path.home() / "ald_app" / "templates"))

class QueryIn(BaseModel):
    question: str

@app.get("/")
def root():
    return RedirectResponse(url="/view")

# Ïª¨ÎüºÎ≥Ñ Î∞òÏò¨Î¶º Í∑úÏπô Î∞è Îã®ÏúÑ
COL_FORMAT = {
    "pressact": {"decimals": 3, "unit": "mTorr"},
    "pressset": {"decimals": 3, "unit": "mTorr"},
    "vg11": {"decimals": 2, "unit": ""},
    "vg12": {"decimals": 2, "unit": ""},
    "vg13": {"decimals": 2, "unit": ""},
    "apcvalvemon": {"decimals": 2, "unit": "%"},
    "apcvalveset": {"decimals": 2, "unit": "%"},
}

def format_value(value: float, col: Optional[str] = None, agg: str = "avg") -> str:
    """Í∞í Ìè¨Îß∑ÌåÖ (Î∞òÏò¨Î¶º + Îã®ÏúÑ)"""
    if value is None or (isinstance(value, float) and (value != value)):  # NaN Ï≤¥ÌÅ¨
        return "N/A"
    
    # null_ratioÎäî ÌçºÏÑºÌä∏
    if agg == "null_ratio":
        return f"{value:.2f}%"
    
    # Ïª¨ÎüºÎ≥Ñ Ìè¨Îß∑ Í∑úÏπô Ï†ÅÏö©
    if col and col in COL_FORMAT:
        fmt = COL_FORMAT[col]
        decimals = fmt["decimals"]
        unit = fmt["unit"]
        formatted = f"{value:.{decimals}f}"
        return f"{formatted}{' ' + unit if unit else ''}"
    
    # Í∏∞Î≥∏: ÏÜåÏàòÏ†ê 2ÏûêÎ¶¨
    return f"{value:.2f}"

def format_row(row: dict, parsed: dict) -> dict:
    """Ìñâ Îç∞Ïù¥ÌÑ∞ Ìè¨Îß∑ÌåÖ (n, std Îì± Ï∂îÍ∞Ä Ï†ïÎ≥¥ Ìè¨Ìï®)"""
    formatted = {}
    col = parsed.get("col") or "pressact"  # Í∏∞Î≥∏Í∞í
    
    for key, value in row.items():
        if key == "value" and col:
            formatted[key] = format_value(value, col, parsed.get("agg", "avg"))
        elif key in ("std", "min_val", "max_val", "avg_diff", "min_diff", "max_diff") and col:
            formatted[key] = format_value(value, col, "avg")
        elif key in ("diff", "diff_signed"):
            # ÎπÑÍµê Ï∞®Ïù¥Îäî ÏõêÎ≥∏ Ïª¨Îüº Í∏∞Ï§ÄÏúºÎ°ú Ìè¨Îß∑ÌåÖ
            formatted[key] = format_value(value, col, "avg") if col else f"{value:.2f}"
        elif key == "n" or key == "outlier_count":
            formatted[key] = int(value) if value else 0
        elif key in ("trace1_avg", "trace2_avg") and col:
            formatted[key] = format_value(value, col, "avg")
        else:
            formatted[key] = value
    
    return formatted

def make_summary(parsed: dict, rows: list) -> str:
    agg_kr_map = {
        "avg": "ÌèâÍ∑†", "min": "ÏµúÏÜå", "max": "ÏµúÎåÄ", "count": "Í∞úÏàò",
        "std": "ÌëúÏ§ÄÌé∏Ï∞®", "stddev": "ÌëúÏ§ÄÌé∏Ï∞®", "p50": "Ï§ëÏïôÍ∞í", "median": "Ï§ëÏïôÍ∞í",
        "p95": "95ÌçºÏÑºÌÉÄÏùº", "p99": "99ÌçºÏÑºÌÉÄÏùº", "null_ratio": "Í≤∞Ï∏°Î•†"
    }
    agg_kr = agg_kr_map.get(parsed["agg"], parsed["agg"])
    col = parsed.get("col") or "*"
    scope = []
    if parsed.get("trace_id"):
        scope.append(parsed["trace_id"])
    if parsed.get("step_name"):
        scope.append(f"step={parsed['step_name']}")
    scope_txt = (", ".join(scope) + " Í∏∞Ï§Ä ") if scope else ""

    if not rows:
        return f"Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§. ({scope_txt}{col} {agg_kr})"

    if parsed.get("group_by"):
        top = rows[0]
        key = parsed["group_by"]
        key_kr = "Í≥µÏ†ï ID" if key == "trace_id" else ("Îã®Í≥ÑÎ™Ö" if key == "step_name" else key)
        summary = f"{scope_txt}{col} {agg_kr} ({key_kr}Î≥Ñ Top {len(rows)}). 1ÏúÑ={top.get(key)}: {top.get('value')}"
        
        # Ï∂îÍ∞Ä ÌÜµÍ≥Ñ Ï†ïÎ≥¥ (n, std, min, max)Í∞Ä ÏûàÏúºÎ©¥ ÌëúÏãú
        if "n" in top:
            summary += f" (n={top['n']})"
        if "std" in top and top.get("std"):
            summary += f" [std={top['std']}]"
        if "min_val" in top and "max_val" in top:
            summary += f" [Î≤îÏúÑ: {top['min_val']} ~ {top['max_val']}]"
        return summary
    
    # trace ÎπÑÍµê ÏºÄÏù¥Ïä§
    if parsed.get("is_trace_compare") and rows:
        top = rows[0]
        trace_ids = parsed.get("trace_ids", [])
        if len(trace_ids) >= 2:
            step_name = top.get('step_name', '')
            diff_val = top.get('diff', 0)
            trace1_avg = top.get('trace1_avg', 0)
            trace2_avg = top.get('trace2_avg', 0)
            
            # Ìï¥ÏÑù Ï∂îÍ∞Ä
            diff_str = f"{diff_val:.1f}" if isinstance(diff_val, (int, float)) else str(diff_val)
            trace1_str = f"{trace_ids[0]}"
            trace2_str = f"{trace_ids[1]}"
            
            # Ìï¥ÏÑù ÌÖçÏä§Ìä∏ ÏÉùÏÑ±
            interpretation = ""
            if step_name == "STANDBY":
                interpretation = "Ïù¥Îäî ÎåÄÍ∏∞ Îã®Í≥ÑÏóêÏÑú ÏßÑÍ≥µ ÏïàÏ†ïÌôî ÎòêÎäî Î∞∞Í∏∞ Ï†úÏñ¥ Ï∞®Ïù¥Í∞Ä ÏûàÏóàÏùÑ Í∞ÄÎä•ÏÑ±ÏùÑ ÏãúÏÇ¨Ìï©ÎãàÎã§."
            elif step_name in ["B.FILL", "B.FILL4", "B.FILL5"]:
                interpretation = "Ïù¥Îäî Ï∂©ÏßÑ Îã®Í≥ÑÏóêÏÑú ÏïïÎ†• Ï†úÏñ¥ ÌîÑÎ°úÌååÏùº Ï∞®Ïù¥Í∞Ä ÏûàÏóàÏùÑ Í∞ÄÎä•ÏÑ±ÏùÑ ÏãúÏÇ¨Ìï©ÎãàÎã§."
            elif step_name in ["B.UP", "B.DOWN"]:
                interpretation = "Ïù¥Îäî ÏïïÎ†• Î≥ÄÌôî Îã®Í≥ÑÏóêÏÑú Ï†úÏñ¥ ÏÜçÎèÑ ÎòêÎäî Î™©ÌëúÍ∞í Ï∞®Ïù¥Í∞Ä ÏûàÏóàÏùÑ Í∞ÄÎä•ÏÑ±ÏùÑ ÏãúÏÇ¨Ìï©ÎãàÎã§."
            else:
                interpretation = "Ïù¥Îäî Ìï¥Îãπ Îã®Í≥ÑÏóêÏÑú Í≥µÏ†ï Ï°∞Í±¥ ÎòêÎäî Ï†úÏñ¥ ÌååÎùºÎØ∏ÌÑ∞ Ï∞®Ïù¥Í∞Ä ÏûàÏóàÏùÑ Í∞ÄÎä•ÏÑ±ÏùÑ ÏãúÏÇ¨Ìï©ÎãàÎã§."
            
            summary = f"{step_name} Îã®Í≥ÑÏóêÏÑú trace Í∞Ñ pressact Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÌÅΩÎãàÎã§ (Ï∞®Ïù¥: ‚âà{diff_str} mTorr, {trace1_str}: {trace1_avg:.1f} mTorr, {trace2_str}: {trace2_avg:.1f} mTorr). {interpretation}"
            return summary
    
    # Ïù¥ÏÉÅÏπò ÌÉêÏßÄ ÏºÄÏù¥Ïä§
    if parsed.get("is_outlier"):
        if not rows:
            return "Ïù¥ÏÉÅÏπòÍ∞Ä Î∞úÍ≤¨ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. (z-score > 1.0 Í∏∞Ï§Ä)"
        top = rows[0]
        summary = f"Ïù¥ÏÉÅÏπò ÎπÑÏú® Top {len(rows)}. 1ÏúÑ trace={top.get('trace_id')}: {top.get('value')}% (n={top.get('n')}, Ïù¥ÏÉÅÏπò={top.get('outlier_count')})"
        return summary

    r0 = rows[0]
    if "value" in r0:
        summary = f"{scope_txt}{col} {agg_kr}={r0['value']}"
        if "n" in r0:
            summary += f" (n={r0['n']})"
        if "std" in r0 and r0.get("std"):
            summary += f" [std={r0['std']}]"
        return summary
    if "n" in r0:
        return f"{scope_txt}{col} {agg_kr}={r0['n']}"
    return "ÏöîÏïΩ ÏÉùÏÑ± Ïã§Ìå®"

@app.post("/query")
def query(q: QueryIn):
    try:
        parsed_obj = parse_question(q.question)
    except Exception as e:
        return {
            "ok": False,
            "error": str(e),
            "hint_examples": [
                "standard_trace_001 pressact ÌèâÍ∑†",
                "standard_trace_001 Ïä§ÌÖùÎ≥Ñ pressact ÌèâÍ∑†",
                "Í≥µÏ†ïÎ≥Ñ pressact ÌèâÍ∑† top5",
                "standard_trace_001 step=STANDBY pressact ÏµúÎåÄ",
                "pressact ÌëúÏ§ÄÌé∏Ï∞®",
                "pressact Ï§ëÏïôÍ∞í",
            ],
        }

    # Í≥µÏ†ï ÏπúÌôî ÏßÄÌëú ÎòêÎäî Ïù¥ÏÉÅÏπò ÌÉêÏßÄ Ï≤òÎ¶¨
    if parsed_obj.is_trace_compare:
        sql, params = build_trace_compare_sql(parsed_obj)
    elif parsed_obj.is_outlier:
        sql, params = build_outlier_detection_sql(parsed_obj)
    elif parsed_obj.is_dwell_time:
        sql, params = build_dwell_time_sql(parsed_obj)
    elif parsed_obj.is_overshoot:
        sql, params = build_overshoot_sql(parsed_obj)
    elif parsed_obj.is_stable_avg:
        sql, params = build_stable_avg_sql(parsed_obj)
    else:
        sql, params = build_sql(parsed_obj)

    con = duckdb.connect(str(DB))
    try:
        df = con.execute(sql, params).df()
        rows_raw = df.to_dict(orient="records")
        parsed = parsed_obj.__dict__
        # Ìè¨Îß∑ÌåÖ Ï†ÅÏö©
        rows = [format_row(row, parsed) for row in rows_raw]
    finally:
        con.close()
    
    parsed = parsed_obj.__dict__
    summary = make_summary(parsed, rows_raw)  # summaryÎäî ÏõêÎ≥∏ Í∞í ÏÇ¨Ïö©

    return {
        "ok": True,
        "question": q.question,
        "parsed": parsed,
        "sql": sql.strip(),
        "rows": rows,
        "summary": summary,
    }

# ‚úÖ HTML ÌÖåÏù¥Î∏î UI
@app.get("/view", response_class=HTMLResponse)
def view(request: Request, q: str | None = None, show_all: str | None = None):
    if not q:
        return templates.TemplateResponse("index.html", {"request": request, "q": ""})

    try:
        parsed_obj = parse_question(q)
        
        # Ïä§ÌÖùÎ≥Ñ ÏøºÎ¶¨Îäî Í∏∞Î≥∏Í∞í top10 Ï†ÅÏö© (Î™ÖÏãúÏ†ÅÏúºÎ°ú ÏßÄÏ†ïÌïòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞)
        # show_all=1Ïù¥Î©¥ Ï†ÑÏ≤¥ Î≥¥Í∏∞
        if parsed_obj.group_by == "step_name" and parsed_obj.top_n is None:
            if show_all != "1":
                parsed_obj.top_n = 10
                show_all_button = True
                add_others = True  # Others Í∑∏Î£π Ï∂îÍ∞Ä
            else:
                show_all_button = False
                add_others = False
        else:
            show_all_button = False
            add_others = False
        
        # Í≥µÏ†ï ÏπúÌôî ÏßÄÌëú ÎòêÎäî Ïù¥ÏÉÅÏπò ÌÉêÏßÄ Ï≤òÎ¶¨ (Ïö∞ÏÑ†ÏàúÏúÑ: trace_compare > overshoot > outlier > Í∏∞ÌÉÄ)
        if parsed_obj.is_trace_compare:
            sql, params = build_trace_compare_sql(parsed_obj)
        elif parsed_obj.is_overshoot:
            sql, params = build_overshoot_sql(parsed_obj)
        elif parsed_obj.is_outlier:
            sql, params = build_outlier_detection_sql(parsed_obj)
        elif parsed_obj.is_dwell_time:
            sql, params = build_dwell_time_sql(parsed_obj)
        elif parsed_obj.is_stable_avg:
            sql, params = build_stable_avg_sql(parsed_obj)
        else:
            sql, params = build_sql(parsed_obj)
        
        con = duckdb.connect(str(DB))
        try:
            df = con.execute(sql, params).df()
            
            # Others Í∑∏Î£π Ï∂îÍ∞Ä (Ïä§ÌÖùÎ≥ÑÏù¥Í≥† top_nÏù¥ ÏûàÏùÑ Îïå)
            if add_others and parsed_obj.group_by == "step_name" and parsed_obj.top_n:
                # y_col Î®ºÏ†Ä Ï∞æÍ∏∞
                y_col_temp = "value" if "value" in df.columns else ("n" if "n" in df.columns else df.columns[-1])
                x_col_temp = df.columns[0]
                
                # Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞ (LIMIT Ï†úÍ±∞)
                sql_all = sql
                if "LIMIT" in sql_all.upper():
                    # LIMIT Ï†à Ï†úÍ±∞
                    import re
                    sql_all = re.sub(r'\s+LIMIT\s+\d+', '', sql_all, flags=re.IGNORECASE)
                
                df_all = con.execute(sql_all, params).df()
                
                if len(df_all) > len(df):
                    # ÎÇòÎ®∏ÏßÄ Îç∞Ïù¥ÌÑ∞Ïùò ÌèâÍ∑† Í≥ÑÏÇ∞
                    others_df = df_all.iloc[len(df):]
                    others_avg = others_df[y_col_temp].mean() if y_col_temp in others_df.columns else 0
                    others_count = others_df["n"].sum() if "n" in others_df.columns else len(others_df)
                    others_std = others_df["std"].mean() if "std" in others_df.columns else None
                    
                    # Others Ìñâ Ï∂îÍ∞Ä
                    others_row = {x_col_temp: "Others (Í∏∞ÌÉÄ)", y_col_temp: others_avg}
                    if "n" in df_all.columns:
                        others_row["n"] = others_count
                    if "std" in df_all.columns and others_std is not None:
                        others_row["std"] = others_std
                    if "min_val" in df_all.columns:
                        others_row["min_val"] = others_df["min_val"].min() if "min_val" in others_df.columns else None
                    if "max_val" in df_all.columns:
                        others_row["max_val"] = others_df["max_val"].max() if "max_val" in others_df.columns else None
                    
                    df = pd.concat([df, pd.DataFrame([others_row])], ignore_index=True)
            
            rows_raw = df.to_dict(orient="records")
            # Ìè¨Îß∑ÌåÖ Ï†ÅÏö©
            parsed = parsed_obj.__dict__
            rows = [format_row(row, parsed) for row in rows_raw]
        finally:
            con.close()
        
        parsed = parsed_obj.__dict__
        summary = make_summary(parsed, rows_raw)
        return templates.TemplateResponse(
            "index.html",
            {
                "request": request, 
                "q": q, 
                "parsed": parsed, 
                "sql": sql.strip(), 
                "rows": rows, 
                "rows_raw": rows_raw,  # ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ (ÌïÑÌÑ∞ÎßÅ/Ï†ïÎ†¨Ïö©)
                "summary": summary,
                "show_all_button": show_all_button,
            },
        )
    except Exception as e:
        return templates.TemplateResponse("index.html", {"request": request, "q": q, "error": str(e)})

# ‚úÖ PNG plot (Î∏åÎùºÏö∞Ï†ÄÏóêÏÑú Î∞îÎ°ú Ïó¥Î¶¨Îäî ÏóîÎìúÌè¨Ïù∏Ìä∏)
@app.get("/plot")
def plot(q: str):
    try:
        parsed_obj = parse_question(q)
        
        # Í≥µÏ†ï ÏπúÌôî ÏßÄÌëú ÎòêÎäî Ïù¥ÏÉÅÏπò ÌÉêÏßÄ Ï≤òÎ¶¨
        if parsed_obj.is_trace_compare:
            sql, params = build_trace_compare_sql(parsed_obj)
            # ÎπÑÍµêÎäî Î∞î Ï∞®Ìä∏
            parsed_obj.chart_type = "bar"
        elif parsed_obj.is_overshoot:
            sql, params = build_overshoot_sql(parsed_obj)
            # overshootÏùÄ Ïä§ÌÖùÎ≥ÑÏù¥ÎØÄÎ°ú Í∞ÄÎ°ú ÎßâÎåÄ
            parsed_obj.chart_type = "bar"
        elif parsed_obj.is_outlier:
            sql, params = build_outlier_detection_sql(parsed_obj)
            # Ïù¥ÏÉÅÏπòÎäî traceÎ≥ÑÏù¥ÎØÄÎ°ú Î∞î Ï∞®Ìä∏
            parsed_obj.chart_type = "bar"
        elif parsed_obj.is_dwell_time:
            sql, params = build_dwell_time_sql(parsed_obj)
            parsed_obj.chart_type = "bar"
        elif parsed_obj.is_stable_avg:
            sql, params = build_stable_avg_sql(parsed_obj)
        else:
            sql, params = build_sql(parsed_obj)

        con = duckdb.connect(str(DB))
        try:
            df = con.execute(sql, params).df()
        finally:
            con.close()

        if df.empty:
            return Response(content=b"No data", media_type="text/plain")

        # Îã®Ïùº Í∞íÏù¥Î©¥ Í∞ÑÎã® ÌÖçÏä§Ìä∏Î°ú
        if len(df.columns) == 1 and df.columns[0] in ("value", "n"):
            txt = df.to_string(index=False)
            return Response(content=txt.encode("utf-8"), media_type="text/plain; charset=utf-8")

        # Í∑∏Î£π Í≤∞Í≥º: xÏ∂ï(Ï≤´Î≤àÏß∏ Ïª¨Îüº), yÏ∂ï(value or n)
        x_col = df.columns[0]
        y_col = "value" if "value" in df.columns else ("n" if "n" in df.columns else df.columns[-1])

        # üî• ÌïµÏã¨ Î≥ÄÍ≤Ω: Î∂ÑÏÑù Ïú†Ìòï Í∏∞Î∞ò Ï∞®Ìä∏ ÌÖúÌîåÎ¶ø ÏÇ¨Ïö©
        config = get_chart_template(parsed_obj.analysis_type)
        
        # üî• Rule 1: step Í∞úÏàò > 12Î©¥ ‚Üí ÏöîÏïΩ Í∑∏ÎûòÌîÑ (group_profileÏù¥ÏßÄÎßå stepÏù¥ ÎßéÏùÑ Îïå)
        add_others_for_chart = False
        df_all_for_others = None
        if parsed_obj.analysis_type == "group_profile" and parsed_obj.group_by == "step_name" and len(df) > 12:
            # ÏöîÏïΩ Î™®ÎìúÎ°ú Ï†ÑÌôò: Top 7 + Others
            if not parsed_obj.top_n:  # ÏÇ¨Ïö©ÏûêÍ∞Ä Î™ÖÏãúÌïòÏßÄ ÏïäÏïòÏúºÎ©¥
                config = get_chart_template("ranking")  # ranking Ïä§ÌÉÄÏùºÎ°ú Ï†ÑÌôò
                config["chart_type"] = "horizontal_bar"  # Í∞ÄÎ°ú ÎßâÎåÄÎ°ú
                parsed_obj.top_n = 7  # Top 7Îßå ÌëúÏãú
                add_others_for_chart = True  # Others Ï∂îÍ∞Ä ÌîåÎûòÍ∑∏
                # ÎÇòÎ®∏ÏßÄÎäî OthersÎ°ú Î¨∂Í∏∞ ÏúÑÌï¥ ÏõêÎ≥∏ Ï†ÄÏû• (Í∞í Í∏∞Ï§Ä Ï†ïÎ†¨ ÌïÑÏöî)
                df_all_for_others = df.copy()
                # Í∞í Í∏∞Ï§ÄÏúºÎ°ú Ï†ïÎ†¨ (ÎÇ¥Î¶ºÏ∞®Ïàú)
                df = df.sort_values(y_col, ascending=False).head(7) if len(df) > 7 else df.sort_values(y_col, ascending=False)
        
        # ÌÖúÌîåÎ¶ø ÏÑ§Ï†ïÏóê Îî∞Îùº Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
        if config["use_top_n"] and parsed_obj.top_n and len(df) > parsed_obj.top_n:
            df = df.head(parsed_obj.top_n)
        elif len(df) > 100:
            df = df.head(100)  # ÏµúÎåÄ 100Í∞ú
        
        # ÌïúÍ∏Ä Î†àÏù¥Î∏î Îß§Ìïë
        agg_kr = {"avg": "ÌèâÍ∑†", "min": "ÏµúÏÜå", "max": "ÏµúÎåÄ", "count": "Í∞úÏàò"}.get(parsed_obj.agg, parsed_obj.agg)
        col_kr = parsed_obj.col or "Ï†ÑÏ≤¥"
        x_col_kr = "Í≥µÏ†ï ID" if x_col == "trace_id" else ("Îã®Í≥ÑÎ™Ö" if x_col == "step_name" else ("ÏùºÏûê" if x_col == "date" else ("ÏãúÍ∞Ñ" if x_col == "hour" else x_col)))
        y_col_kr = f"{col_kr} {agg_kr}" if parsed_obj.col else agg_kr

        fig, ax = plt.subplots(figsize=(14, 7))
        fig.patch.set_facecolor('white')
        
        # üî• Î∂ÑÏÑù Ïú†Ìòï Í∏∞Î∞ò Í≥†Ï†ï ÌÖúÌîåÎ¶ø Ï†ÅÏö©
        if config["chart_type"] == "line" or (parsed_obj.group_by in ("date", "hour", "day") or parsed_obj.date_start or parsed_obj.date_end):
            x_vals = df[x_col].tolist()
            y_vals = df[y_col].astype(float).tolist()
            
            # ÎÇ†Ïßú/ÏãúÍ∞ÑÏù¥Î©¥ Ï†ïÎ†¨
            if x_col == "date":
                df = df.sort_values("date")
                x_vals = df[x_col].tolist()
                y_vals = df[y_col].astype(float).tolist()
            
            ax.plot(range(len(x_vals)), y_vals, marker='o', linewidth=2, markersize=6, color='#667eea')
            ax.set_xticks(range(len(x_vals)))
            ax.set_xticklabels([str(x) for x in x_vals], rotation=45, ha='right')
            
            # ÏµúÎåÄÍ∞í ÌëúÏãú
            if y_vals:
                max_idx = y_vals.index(max(y_vals))
                ax.plot(max_idx, y_vals[max_idx], 'ro', markersize=12)
                ax.annotate(f'ÏµúÎåÄ: {y_vals[max_idx]:.2f}', 
                           xy=(max_idx, y_vals[max_idx]),
                           xytext=(max_idx, y_vals[max_idx] + (max(y_vals) - min(y_vals)) * 0.1),
                           fontsize=10, fontweight='bold',
                           bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),
                           ha='center')
        else:
            # üî• ÌÖúÌîåÎ¶ø Ï†ÅÏö© (analysis_type Í∏∞Î∞ò)
            # Others Í∑∏Î£π Ï∂îÍ∞Ä (ÏöîÏïΩ Î™®ÎìúÏùº Îïå)
            if add_others_for_chart and df_all_for_others is not None and len(df_all_for_others) > len(df):
                others_df = df_all_for_others.sort_values(y_col, ascending=False).iloc[len(df):]
                others_value_sum = sum(r for r in others_df[y_col].astype(float).tolist())
                others_avg = others_value_sum / len(others_df) if len(others_df) > 0 else 0
                others_row = {x_col: f"Others ({len(others_df)}Í∞ú)", y_col: others_avg}
                # DataFrameÏóê Others Ìñâ Ï∂îÍ∞Ä
                df = pd.concat([df, pd.DataFrame([others_row])], ignore_index=True)
            
            apply_chart_template(ax, df, x_col, y_col, config, parsed_obj)
        
        # Ï∂ï Î†àÏù¥Î∏î Î∞è Ï†úÎ™© ÏÑ§Ï†ï
        title_lines = []
        filter_parts = []  # Ï¥àÍ∏∞Ìôî ÌïÑÏàò
        
        if parsed_obj.analysis_type == "comparison" and "trace1_avg" in df.columns:
            # ÎπÑÍµê Ï∞®Ìä∏Îäî Î≥ÑÎèÑ Ï≤òÎ¶¨
            ax.set_xlabel("Îã®Í≥ÑÎ™Ö", fontsize=12, fontweight='bold', labelpad=10)
            ax.set_ylabel(f"{col_kr} ÌèâÍ∑† (mTorr)", fontsize=12, fontweight='bold', labelpad=10)
            title_lines = [f"{col_kr} ÌèâÍ∑† ÎπÑÍµê (Îã®Í≥ÑÎ™ÖÎ≥Ñ)"]
            if parsed_obj.trace_ids and len(parsed_obj.trace_ids) >= 2:
                title_lines.append(f"Í≥µÏ†ï: {parsed_obj.trace_ids[0]}, {parsed_obj.trace_ids[1]}")
        else:
            # ÏùºÎ∞ò Ï∞®Ìä∏
            ax.set_xlabel(x_col_kr, fontsize=12, fontweight='bold', labelpad=10)
            ax.set_ylabel(y_col_kr, fontsize=12, fontweight='bold', labelpad=10)
            
            # Ï†úÎ™© ÏÉùÏÑ±
            title_lines.append(f"{y_col_kr} ({x_col_kr}Î≥Ñ)")
            
            if parsed_obj.trace_id:
                filter_parts.append(f"Í≥µÏ†ï: {parsed_obj.trace_id}")
            if len(parsed_obj.trace_ids) > 1 and parsed_obj.analysis_type != "comparison":
                filter_parts.append(f"Í≥µÏ†ï: {', '.join(parsed_obj.trace_ids)}")
            if parsed_obj.step_name:
                filter_parts.append(f"Îã®Í≥Ñ: {parsed_obj.step_name}")
            if len(parsed_obj.step_names) > 1:
                filter_parts.append(f"Îã®Í≥Ñ: {', '.join(parsed_obj.step_names)}")
            if parsed_obj.date_start:
                filter_parts.append(f"ÏãúÏûë: {parsed_obj.date_start}")
            if parsed_obj.date_end:
                filter_parts.append(f"Ï¢ÖÎ£å: {parsed_obj.date_end}")
        
        if filter_parts:
            title_lines.append(" | ".join(filter_parts))
        
        title_text = "\n".join(title_lines)
        ax.set_title(title_text, fontsize=13, fontweight='bold', pad=15, loc='center', wrap=True)
        
        ax.grid(True, alpha=0.3, axis='y', linestyle='--')
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        
        plt.tight_layout(pad=3.0)

        buf = io.BytesIO()
        plt.savefig(buf, format="png", dpi=150, bbox_inches='tight', facecolor='white', pad_inches=0.3)
        plt.close(fig)
        buf.seek(0)
        return Response(content=buf.read(), media_type="image/png")
    except Exception as e:
        # ÏóêÎü¨Í∞Ä Î∞úÏÉùÌïòÎ©¥ ÏóêÎü¨ Î©îÏãúÏßÄÎ•º Ïù¥ÎØ∏ÏßÄÎ°ú Î∞òÌôò
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.text(0.5, 0.5, f'Error: {str(e)}', 
                ha='center', va='center', fontsize=14, color='red',
                transform=ax.transAxes)
        ax.axis('off')
        buf = io.BytesIO()
        plt.savefig(buf, format="png", dpi=150, bbox_inches='tight')
        plt.close(fig)
        buf.seek(0)
        return Response(content=buf.read(), media_type="image/png")

# ‚úÖ plotÏùÑ ÌéòÏù¥ÏßÄÎ°ú Î≥¥Í∏∞(Ïù¥ÎØ∏ÏßÄ ÌÉúÍ∑∏Î°ú Î†åÎçîÎßÅ)
@app.get("/plot_page", response_class=HTMLResponse)
def plot_page(request: Request, q: str):
    return templates.TemplateResponse("plot.html", {"request": request, "q": q})

# ‚úÖ Îç∞Ïù¥ÌÑ∞ ÌÉêÏÉâ: Ïª¨Îüº Î™©Î°ù
@app.get("/api/columns")
def get_columns():
    con = duckdb.connect(str(DB))
    df = con.execute("DESCRIBE traces").df()
    # slugifyÎêú Ïª¨ÎüºÎ™ÖÎßå (Ïã§Ï†ú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Ïª¨ÎüºÎì§)
    cols = [row[0] for row in df.values if not row[0].startswith('_') and row[0] != 'No.']
    return {"columns": cols}

# ‚úÖ Îç∞Ïù¥ÌÑ∞ ÌÉêÏÉâ: Í≥µÏ†ï ID Î™©Î°ù
@app.get("/api/traces")
def get_traces():
    con = duckdb.connect(str(DB))
    df = con.execute("SELECT DISTINCT trace_id FROM traces ORDER BY trace_id").df()
    return {"traces": df['trace_id'].tolist()}

# ‚úÖ Îç∞Ïù¥ÌÑ∞ ÌÉêÏÉâ: Îã®Í≥ÑÎ™Ö Î™©Î°ù
@app.get("/api/steps")
def get_steps():
    con = duckdb.connect(str(DB))
    df = con.execute("SELECT DISTINCT step_name FROM traces ORDER BY step_name").df()
    return {"steps": df['step_name'].tolist()}

# ‚úÖ Îç∞Ïù¥ÌÑ∞ ÌÉêÏÉâ: Îç∞Ïù¥ÌÑ∞ Î≤îÏúÑ
@app.get("/api/range")
def get_data_range():
    con = duckdb.connect(str(DB))
    min_date = con.execute("SELECT MIN(DATE(timestamp)) as min_date FROM traces").fetchone()[0]
    max_date = con.execute("SELECT MAX(DATE(timestamp)) as max_date FROM traces").fetchone()[0]
    total_rows = con.execute("SELECT COUNT(*) as cnt FROM traces").fetchone()[0]
    return {
        "min_date": str(min_date) if min_date else None,
        "max_date": str(max_date) if max_date else None,
        "total_rows": total_rows
    }

# ‚úÖ CSV Îã§Ïö¥Î°úÎìú
@app.get("/api/csv")
def download_csv(q: str):
    try:
        parsed_obj = parse_question(q)
        
        # Í≥µÏ†ï ÏπúÌôî ÏßÄÌëú ÎòêÎäî Ïù¥ÏÉÅÏπò ÌÉêÏßÄ Ï≤òÎ¶¨ (Ïö∞ÏÑ†ÏàúÏúÑ: trace_compare > overshoot > outlier > Í∏∞ÌÉÄ)
        if parsed_obj.is_trace_compare:
            sql, params = build_trace_compare_sql(parsed_obj)
        elif parsed_obj.is_overshoot:
            sql, params = build_overshoot_sql(parsed_obj)
        elif parsed_obj.is_outlier:
            sql, params = build_outlier_detection_sql(parsed_obj)
        elif parsed_obj.is_dwell_time:
            sql, params = build_dwell_time_sql(parsed_obj)
        elif parsed_obj.is_stable_avg:
            sql, params = build_stable_avg_sql(parsed_obj)
        else:
            sql, params = build_sql(parsed_obj)
        
        con = duckdb.connect(str(DB))
        df = con.execute(sql, params).df()
        
        csv_str = df.to_csv(index=False)
        return Response(content=csv_str, media_type="text/csv", 
                       headers={"Content-Disposition": f"attachment; filename=query_result.csv"})
    except Exception as e:
        return {"ok": False, "error": str(e)}

# ‚úÖ ÌûàÏä§ÌÜ†Î¶¨ Ï†ÄÏû•/Ï°∞Ìöå (Í∞ÑÎã®Ìïú JSON ÌååÏùº Í∏∞Î∞ò)
HISTORY_FILE = Path.home() / "ald_app" / "data" / "history.json"

@app.post("/api/history")
def save_history(q: QueryIn):
    try:
        if not HISTORY_FILE.parent.exists():
            HISTORY_FILE.parent.mkdir(parents=True)
        
        history = []
        if HISTORY_FILE.exists():
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                history = json.load(f)
        
        # Ï§ëÎ≥µ Ï†úÍ±∞ Î∞è ÏµúÍ∑º Í≤ÉÎßå Ïú†ÏßÄ (ÏµúÎåÄ 100Í∞ú)
        history = [h for h in history if h['question'] != q.question]
        history.insert(0, {"question": q.question, "timestamp": datetime.now().isoformat()})
        history = history[:100]
        
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        return {"ok": True}
    except Exception as e:
        return {"ok": False, "error": str(e)}

@app.get("/api/history")
def get_history():
    try:
        if not HISTORY_FILE.exists():
            return {"history": []}
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            history = json.load(f)
        return {"history": history[:20]}  # ÏµúÍ∑º 20Í∞úÎßå
    except Exception as e:
        return {"ok": False, "error": str(e)}

# ‚úÖ Ï¶êÍ≤®Ï∞æÍ∏∞ Ï†ÄÏû•/Ï°∞Ìöå
FAVORITES_FILE = Path.home() / "ald_app" / "data" / "favorites.json"

@app.post("/api/favorites")
def save_favorite(q: QueryIn):
    try:
        if not FAVORITES_FILE.parent.exists():
            FAVORITES_FILE.parent.mkdir(parents=True)
        
        favorites = []
        if FAVORITES_FILE.exists():
            with open(FAVORITES_FILE, 'r', encoding='utf-8') as f:
                favorites = json.load(f)
        
        if q.question not in favorites:
            favorites.append(q.question)
        
        with open(FAVORITES_FILE, 'w', encoding='utf-8') as f:
            json.dump(favorites, f, ensure_ascii=False, indent=2)
        
        return {"ok": True}
    except Exception as e:
        return {"ok": False, "error": str(e)}

@app.get("/api/favorites")
def get_favorites():
    try:
        if not FAVORITES_FILE.exists():
            return {"favorites": []}
        with open(FAVORITES_FILE, 'r', encoding='utf-8') as f:
            favorites = json.load(f)
        return {"favorites": favorites}
    except Exception as e:
        return {"ok": False, "error": str(e)}

@app.delete("/api/favorites")
def delete_favorite(q: QueryIn):
    try:
        if not FAVORITES_FILE.exists():
            return {"ok": True}
        
        with open(FAVORITES_FILE, 'r', encoding='utf-8') as f:
            favorites = json.load(f)
        
        favorites = [f for f in favorites if f != q.question]
        
        with open(FAVORITES_FILE, 'w', encoding='utf-8') as f:
            json.dump(favorites, f, ensure_ascii=False, indent=2)
        
        return {"ok": True}
    except Exception as e:
        return {"ok": False, "error": str(e)}
