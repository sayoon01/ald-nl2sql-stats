from pathlib import Path
from typing import Optional
from fastapi import FastAPI, Request  # type: ignore
from fastapi.responses import Response, HTMLResponse, RedirectResponse  # type: ignore
from fastapi.templating import Jinja2Templates  # type: ignore
from pydantic import BaseModel  # type: ignore
import duckdb  # type: ignore
import pandas as pd  # type: ignore
import matplotlib  # type: ignore
matplotlib.use('Agg')  # ì„œë²„ í™˜ê²½ì—ì„œ í•„ìš”í•œ ë°±ì—”ë“œ ì„¤ì •
import matplotlib.pyplot as plt  # type: ignore
import matplotlib.font_manager as fm  # type: ignore
import io
import json
from datetime import datetime

# í•œê¸€ í°íŠ¸ ì„¤ì • (Linux í™˜ê²½)
# Linuxì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ìš°ì„  ì‹œë„
try:
    import matplotlib.font_manager as fm
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ëª©ë¡
    font_list = [f.name for f in fm.fontManager.ttflist]
    
    # í•œê¸€ ì§€ì› í°íŠ¸ ìš°ì„ ìˆœìœ„
    korean_font_candidates = [
        'NanumGothic',
        'NanumBarunGothic', 
        'Noto Sans CJK KR',
        'Noto Sans CJK JP',  # ì¼ë³¸ì–´ í°íŠ¸ë„ í•œê¸€ ì§€ì›
        'Noto Sans CJK SC',  # ì¤‘êµ­ì–´ ê°„ì²´ë„ í•œê¸€ ì§€ì›
        'Noto Sans CJK TC',  # ì¤‘êµ­ì–´ ë²ˆì²´ë„ í•œê¸€ ì§€ì›
        'Noto Sans CJK',     # ì¼ë°˜ Noto Sans CJK
    ]
    
    # í°íŠ¸ ì°¾ê¸° (ë¶€ë¶„ ë§¤ì¹­ í¬í•¨)
    selected_font = None
    for candidate in korean_font_candidates:
        # ì •í™•í•œ ë§¤ì¹­
        if candidate in font_list:
            selected_font = candidate
            break
        # ë¶€ë¶„ ë§¤ì¹­ (ì˜ˆ: "Noto Sans CJK"ë¡œ ì‹œì‘í•˜ëŠ” í°íŠ¸)
        for font_name in font_list:
            if candidate.lower() in font_name.lower() or font_name.lower() in candidate.lower():
                selected_font = font_name
                break
        if selected_font:
            break
    
    if selected_font:
        plt.rcParams['font.family'] = selected_font
        print(f"[Font] í•œê¸€ í°íŠ¸ ì„¤ì •: {selected_font}")
    else:
        # í°íŠ¸ íŒŒì¼ ê²½ë¡œì—ì„œ ì§ì ‘ ì°¾ê¸°
        for font_prop in fm.fontManager.ttflist:
            font_path = str(font_prop.fname).lower()
            if 'noto' in font_path and ('cjk' in font_path or 'korean' in font_path):
                plt.rcParams['font.family'] = font_prop.name
                print(f"[Font] í•œê¸€ í°íŠ¸ ì„¤ì • (ê²½ë¡œ ê¸°ë°˜): {font_prop.name}")
                break
        else:
            # ë§ˆì§€ë§‰ fallback: DejaVu Sans (í•œê¸€ ë¯¸ì§€ì›ì´ì§€ë§Œ ê¹¨ì§€ì§€ ì•Šê²Œ)
            plt.rcParams['font.family'] = 'DejaVu Sans'
            print("[Font] í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ DejaVu Sans ì‚¬ìš© (í•œê¸€ ê¹¨ì§ ê°€ëŠ¥)")
            
except Exception as e:
    plt.rcParams['font.family'] = 'DejaVu Sans'
    print(f"[Font] í°íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}, DejaVu Sans ì‚¬ìš©")

plt.rcParams['axes.unicode_minus'] = False  # ìŒìˆ˜ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# í°íŠ¸ ìºì‹œ ì¬ë¡œë“œ (í•œê¸€ í°íŠ¸ê°€ ì œëŒ€ë¡œ ì ìš©ë˜ë„ë¡)
try:
    fm._rebuild()
except:
    pass
# ê¸°ì¡´ íŒŒì„œì™€ ìƒˆ íŒŒì„œ ì„ íƒ ê°€ëŠ¥
try:
    from src.nl_parse_v2 import parse_question  # ìƒˆ ë„ë©”ì¸ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ íŒŒì„œ
except ImportError:
    from src.nl_parse import parse_question  # ê¸°ì¡´ íŒŒì„œ (fallback)

# ì •ê·œí™” í•¨ìˆ˜ import
from domain.rules.normalization import normalize
from src.sql_builder import build_sql
from src.process_metrics import (
    build_stable_avg_sql,
    build_overshoot_sql,
    build_dwell_time_sql,
    build_outlier_detection_sql,
    build_trace_compare_sql,
)
from src.chart_templates import get_chart_template, apply_chart_template

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
DB = PROJECT_ROOT / "data_out" / "ald.duckdb"

app = FastAPI(title="ALD NLâ†’SQL Stats API")
templates = Jinja2Templates(directory=str(PROJECT_ROOT / "templates"))

class QueryIn(BaseModel):
    question: str

@app.get("/")
def root():
    return RedirectResponse(url="/view")

# ì»¬ëŸ¼ë³„ ë°˜ì˜¬ë¦¼ ê·œì¹™ ë° ë‹¨ìœ„
COL_FORMAT = {
    "pressact": {"decimals": 3, "unit": "mTorr"},
    "pressset": {"decimals": 3, "unit": "mTorr"},
    "vg11": {"decimals": 2, "unit": ""},
    "vg12": {"decimals": 2, "unit": ""},
    "vg13": {"decimals": 2, "unit": ""},
    "apcvalvemon": {"decimals": 2, "unit": "%"},
    "apcvalveset": {"decimals": 2, "unit": "%"},
}

def format_value(value: float, col: Optional[str] = None, agg: str = "avg") -> str:
    """ê°’ í¬ë§·íŒ… (ë°˜ì˜¬ë¦¼ + ë‹¨ìœ„)"""
    if value is None or (isinstance(value, float) and (value != value)):  # NaN ì²´í¬
        return "N/A"
    
    # null_ratioëŠ” í¼ì„¼íŠ¸
    if agg == "null_ratio":
        return f"{value:.2f}%"
    
    # ì»¬ëŸ¼ë³„ í¬ë§· ê·œì¹™ ì ìš©
    if col and col in COL_FORMAT:
        fmt = COL_FORMAT[col]
        decimals = fmt["decimals"]
        unit = fmt["unit"]
        formatted = f"{value:.{decimals}f}"
        return f"{formatted}{' ' + unit if unit else ''}"
    
    # ê¸°ë³¸: ì†Œìˆ˜ì  2ìë¦¬
    return f"{value:.2f}"

def format_row(row: dict, parsed: dict) -> dict:
    """í–‰ ë°ì´í„° í¬ë§·íŒ… (n, std ë“± ì¶”ê°€ ì •ë³´ í¬í•¨)"""
    formatted = {}
    col = parsed.get("col") or "pressact"  # ê¸°ë³¸ê°’
    
    for key, value in row.items():
        if key == "value" and col:
            formatted[key] = format_value(value, col, parsed.get("agg", "avg"))
        elif key in ("std", "min_val", "max_val", "avg_diff", "min_diff", "max_diff") and col:
            formatted[key] = format_value(value, col, "avg")
        elif key in ("diff", "diff_signed"):
            # ë¹„êµ ì°¨ì´ëŠ” ì›ë³¸ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ í¬ë§·íŒ…
            formatted[key] = format_value(value, col, "avg") if col else f"{value:.2f}"
        elif key == "n" or key == "outlier_count":
            formatted[key] = int(value) if value else 0
        elif key in ("trace1_avg", "trace2_avg") and col:
            formatted[key] = format_value(value, col, "avg")
        else:
            formatted[key] = value
    
    return formatted

def make_summary(parsed: dict, rows: list) -> str:
    agg_kr_map = {
        "avg": "í‰ê· ", "min": "ìµœì†Œ", "max": "ìµœëŒ€", "count": "ê°œìˆ˜",
        "std": "í‘œì¤€í¸ì°¨", "stddev": "í‘œì¤€í¸ì°¨", "p50": "ì¤‘ì•™ê°’", "median": "ì¤‘ì•™ê°’",
        "p95": "95í¼ì„¼íƒ€ì¼", "p99": "99í¼ì„¼íƒ€ì¼", "null_ratio": "ê²°ì¸¡ë¥ "
    }
    agg_kr = agg_kr_map.get(parsed["agg"], parsed["agg"])
    col = parsed.get("col") or "*"
    scope = []
    if parsed.get("trace_id"):
        scope.append(parsed["trace_id"])
    if parsed.get("step_name"):
        scope.append(f"step={parsed['step_name']}")
    scope_txt = (", ".join(scope) + " ê¸°ì¤€ ") if scope else ""

    if not rows:
        return f"ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ({scope_txt}{col} {agg_kr})"

    if parsed.get("group_by"):
        top = rows[0]
        key = parsed["group_by"]
        key_kr = "ê³µì • ID" if key == "trace_id" else ("ë‹¨ê³„ëª…" if key == "step_name" else key)
        
        # ìš”ì²­í•œ top_nê³¼ ì‹¤ì œ ë°˜í™˜ëœ ê°œìˆ˜ ë¹„êµ
        requested_top_n = parsed.get("top_n")
        actual_count = len(rows)
        
        if requested_top_n and actual_count < requested_top_n:
            summary = f"{scope_txt}{col} {agg_kr} ({key_kr}ë³„ Top {requested_top_n} ìš”ì²­, ì‹¤ì œ {actual_count}ê°œ ë°˜í™˜). 1ìœ„={top.get(key)}: {top.get('value')}"
            summary += f" (ë°ì´í„°ê°€ {requested_top_n}ê°œë³´ë‹¤ ì ìŠµë‹ˆë‹¤)"
        else:
            summary = f"{scope_txt}{col} {agg_kr} ({key_kr}ë³„ Top {actual_count}). 1ìœ„={top.get(key)}: {top.get('value')}"
        
        # ì¶”ê°€ í†µê³„ ì •ë³´ (n, std, min, max)ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if "n" in top:
            summary += f" (n={top['n']})"
        if "std" in top and top.get("std"):
            summary += f" [std={top['std']}]"
        if "min_val" in top and "max_val" in top:
            summary += f" [ë²”ìœ„: {top['min_val']} ~ {top['max_val']}]"
        return summary
    
    # trace ë¹„êµ ì¼€ì´ìŠ¤
    if parsed.get("is_trace_compare") and rows:
        top = rows[0]
        trace_ids = parsed.get("trace_ids", [])
        if len(trace_ids) >= 2:
            step_name = top.get('step_name', '')
            diff_val = top.get('diff', 0)
            trace1_avg = top.get('trace1_avg', 0)
            trace2_avg = top.get('trace2_avg', 0)
            
            # í•´ì„ ì¶”ê°€
            diff_str = f"{diff_val:.1f}" if isinstance(diff_val, (int, float)) else str(diff_val)
            trace1_str = f"{trace_ids[0]}"
            trace2_str = f"{trace_ids[1]}"
            
            # í•´ì„ í…ìŠ¤íŠ¸ ìƒì„±
            interpretation = ""
            if step_name == "STANDBY":
                interpretation = "ì´ëŠ” ëŒ€ê¸° ë‹¨ê³„ì—ì„œ ì§„ê³µ ì•ˆì •í™” ë˜ëŠ” ë°°ê¸° ì œì–´ ì°¨ì´ê°€ ìˆì—ˆì„ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤."
            elif step_name in ["B.FILL", "B.FILL4", "B.FILL5"]:
                interpretation = "ì´ëŠ” ì¶©ì§„ ë‹¨ê³„ì—ì„œ ì••ë ¥ ì œì–´ í”„ë¡œíŒŒì¼ ì°¨ì´ê°€ ìˆì—ˆì„ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤."
            elif step_name in ["B.UP", "B.DOWN"]:
                interpretation = "ì´ëŠ” ì••ë ¥ ë³€í™” ë‹¨ê³„ì—ì„œ ì œì–´ ì†ë„ ë˜ëŠ” ëª©í‘œê°’ ì°¨ì´ê°€ ìˆì—ˆì„ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤."
            else:
                interpretation = "ì´ëŠ” í•´ë‹¹ ë‹¨ê³„ì—ì„œ ê³µì • ì¡°ê±´ ë˜ëŠ” ì œì–´ íŒŒë¼ë¯¸í„° ì°¨ì´ê°€ ìˆì—ˆì„ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤."
            
            summary = f"{step_name} ë‹¨ê³„ì—ì„œ trace ê°„ pressact ì°¨ì´ê°€ ê°€ì¥ í½ë‹ˆë‹¤ (ì°¨ì´: â‰ˆ{diff_str} mTorr, {trace1_str}: {trace1_avg:.1f} mTorr, {trace2_str}: {trace2_avg:.1f} mTorr). {interpretation}"
            return summary
    
    # ì´ìƒì¹˜ íƒì§€ ì¼€ì´ìŠ¤
    if parsed.get("is_outlier"):
        if not rows:
            return "ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (z-score > 1.0 ê¸°ì¤€)"
        top = rows[0]
        summary = f"ì´ìƒì¹˜ ë¹„ìœ¨ Top {len(rows)}. 1ìœ„ trace={top.get('trace_id')}: {top.get('value')}% (n={top.get('n')}, ì´ìƒì¹˜={top.get('outlier_count')})"
        return summary

    r0 = rows[0]
    if "value" in r0:
        summary = f"{scope_txt}{col} {agg_kr}={r0['value']}"
        if "n" in r0:
            summary += f" (n={r0['n']})"
        if "std" in r0 and r0.get("std"):
            summary += f" [std={r0['std']}]"
        return summary
    if "n" in r0:
        return f"{scope_txt}{col} {agg_kr}={r0['n']}"
    return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"

@app.post("/query")
def query(q: QueryIn):
    # ì •ê·œí™”
    norm = normalize(q.question)
    
    try:
        parsed_obj = parse_question(q.question)
    except Exception as e:
        return {
            "ok": False,
            "error": str(e),
            "question": norm.raw,
            "normalized": norm.text,
            "hint_examples": [
                "standard_trace_001 pressact í‰ê· ",
                "standard_trace_001 ìŠ¤í…ë³„ pressact í‰ê· ",
                "ê³µì •ë³„ pressact í‰ê·  top5",
                "standard_trace_001 step=STANDBY pressact ìµœëŒ€",
                "pressact í‘œì¤€í¸ì°¨",
                "pressact ì¤‘ì•™ê°’",
            ],
        }

    # ê³µì • ì¹œí™” ì§€í‘œ ë˜ëŠ” ì´ìƒì¹˜ íƒì§€ ì²˜ë¦¬
    if parsed_obj.is_trace_compare:
        sql, params = build_trace_compare_sql(parsed_obj)
    elif parsed_obj.is_outlier:
        sql, params = build_outlier_detection_sql(parsed_obj)
    elif parsed_obj.is_dwell_time:
        sql, params = build_dwell_time_sql(parsed_obj)
    elif parsed_obj.is_overshoot:
        sql, params = build_overshoot_sql(parsed_obj)
    elif parsed_obj.is_stable_avg:
        sql, params = build_stable_avg_sql(parsed_obj)
    else:
        sql, params = build_sql(parsed_obj)

    con = duckdb.connect(str(DB))
    try:
        df = con.execute(sql, params).df()
        rows_raw = df.to_dict(orient="records")
        parsed = parsed_obj.__dict__
        # í¬ë§·íŒ… ì ìš©
        rows = [format_row(row, parsed) for row in rows_raw]
    finally:
        con.close()
    
    parsed = parsed_obj.__dict__
    summary = make_summary(parsed, rows_raw)  # summaryëŠ” ì›ë³¸ ê°’ ì‚¬ìš©

    return {
        "ok": True,
        "question": norm.raw,  # ì›ë¬¸ ì§ˆë¬¸
        "normalized": norm.text,  # ì •ê·œí™”ëœ ì§ˆë¬¸
        "parsed": parsed,
        "sql": sql.strip(),
        "rows": rows,
        "summary": summary,
    }

# âœ… HTML í…Œì´ë¸” UI
@app.get("/view", response_class=HTMLResponse)
def view(request: Request, q: str | None = None, show_all: str | None = None):
    if not q:
        return templates.TemplateResponse("index.html", {"request": request, "q": ""})

    try:
        parsed_obj = parse_question(q)
        
        # ìŠ¤í…ë³„ ì¿¼ë¦¬ëŠ” ê¸°ë³¸ê°’ top10 ì ìš© (ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì§€ ì•Šì€ ê²½ìš°)
        # show_all=1ì´ë©´ ì „ì²´ ë³´ê¸°
        if parsed_obj.group_by == "step_name" and parsed_obj.top_n is None:
            if show_all != "1":
                parsed_obj.top_n = 10
                show_all_button = True
                add_others = True  # Others ê·¸ë£¹ ì¶”ê°€
            else:
                show_all_button = False
                add_others = False
        else:
            show_all_button = False
            add_others = False
        
        # ê³µì • ì¹œí™” ì§€í‘œ ë˜ëŠ” ì´ìƒì¹˜ íƒì§€ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„: trace_compare > overshoot > outlier > ê¸°íƒ€)
        if parsed_obj.is_trace_compare:
            sql, params = build_trace_compare_sql(parsed_obj)
        elif parsed_obj.is_overshoot:
            sql, params = build_overshoot_sql(parsed_obj)
        elif parsed_obj.is_outlier:
            sql, params = build_outlier_detection_sql(parsed_obj)
        elif parsed_obj.is_dwell_time:
            sql, params = build_dwell_time_sql(parsed_obj)
        elif parsed_obj.is_stable_avg:
            sql, params = build_stable_avg_sql(parsed_obj)
        else:
            sql, params = build_sql(parsed_obj)
        
        con = duckdb.connect(str(DB))
        try:
            df = con.execute(sql, params).df()
            
            # Others ê·¸ë£¹ ì¶”ê°€ (ìŠ¤í…ë³„ì´ê³  top_nì´ ìˆì„ ë•Œ)
            if add_others and parsed_obj.group_by == "step_name" and parsed_obj.top_n:
                # y_col ë¨¼ì € ì°¾ê¸°
                y_col_temp = "value" if "value" in df.columns else ("n" if "n" in df.columns else df.columns[-1])
                x_col_temp = df.columns[0]
                
                # ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (LIMIT ì œê±°)
                sql_all = sql
                if "LIMIT" in sql_all.upper():
                    # LIMIT ì ˆ ì œê±°
                    import re
                    sql_all = re.sub(r'\s+LIMIT\s+\d+', '', sql_all, flags=re.IGNORECASE)
                
                df_all = con.execute(sql_all, params).df()
                
                if len(df_all) > len(df):
                    # ë‚˜ë¨¸ì§€ ë°ì´í„°ì˜ í‰ê·  ê³„ì‚°
                    others_df = df_all.iloc[len(df):]
                    others_avg = others_df[y_col_temp].mean() if y_col_temp in others_df.columns else 0
                    others_count = others_df["n"].sum() if "n" in others_df.columns else len(others_df)
                    others_std = others_df["std"].mean() if "std" in others_df.columns else None
                    
                    # Others í–‰ ì¶”ê°€
                    others_row = {x_col_temp: "Others (ê¸°íƒ€)", y_col_temp: others_avg}
                    if "n" in df_all.columns:
                        others_row["n"] = others_count
                    if "std" in df_all.columns and others_std is not None:
                        others_row["std"] = others_std
                    if "min_val" in df_all.columns:
                        others_row["min_val"] = others_df["min_val"].min() if "min_val" in others_df.columns else None
                    if "max_val" in df_all.columns:
                        others_row["max_val"] = others_df["max_val"].max() if "max_val" in others_df.columns else None
                    
                    df = pd.concat([df, pd.DataFrame([others_row])], ignore_index=True)
            
            rows_raw = df.to_dict(orient="records")
            # í¬ë§·íŒ… ì ìš©
            parsed = parsed_obj.__dict__
            rows = [format_row(row, parsed) for row in rows_raw]
        finally:
            con.close()
        
        parsed = parsed_obj.__dict__
        summary = make_summary(parsed, rows_raw)
        return templates.TemplateResponse(
            "index.html",
            {
                "request": request, 
                "q": q,  # ì›ë¬¸ ì§ˆë¬¸
                "question_raw": norm.raw,  # ì›ë¬¸ ì§ˆë¬¸ (ëª…ì‹œì )
                "question_normalized": norm.text,  # ì •ê·œí™”ëœ ì§ˆë¬¸
                "parsed": parsed, 
                "sql": sql.strip(), 
                "rows": rows, 
                "rows_raw": rows_raw,  # ì›ë³¸ ë°ì´í„° (í•„í„°ë§/ì •ë ¬ìš©)
                "summary": summary,
                "show_all_button": show_all_button,
            },
        )
    except Exception as e:
        return templates.TemplateResponse(
            "index.html", 
            {
                "request": request, 
                "q": q,
                "question_raw": norm.raw,
                "question_normalized": norm.text,
                "error": str(e)
            }
        )

# âœ… PNG plot (ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì—´ë¦¬ëŠ” ì—”ë“œí¬ì¸íŠ¸)
@app.get("/plot")
def plot(q: str):
    try:
        parsed_obj = parse_question(q)
        
        # ê³µì • ì¹œí™” ì§€í‘œ ë˜ëŠ” ì´ìƒì¹˜ íƒì§€ ì²˜ë¦¬
        if parsed_obj.is_trace_compare:
            sql, params = build_trace_compare_sql(parsed_obj)
            # ë¹„êµëŠ” ë°” ì°¨íŠ¸
            parsed_obj.chart_type = "bar"
        elif parsed_obj.is_overshoot:
            sql, params = build_overshoot_sql(parsed_obj)
            # overshootì€ ìŠ¤í…ë³„ì´ë¯€ë¡œ ê°€ë¡œ ë§‰ëŒ€
            parsed_obj.chart_type = "bar"
        elif parsed_obj.is_outlier:
            sql, params = build_outlier_detection_sql(parsed_obj)
            # ì´ìƒì¹˜ëŠ” traceë³„ì´ë¯€ë¡œ ë°” ì°¨íŠ¸
            parsed_obj.chart_type = "bar"
        elif parsed_obj.is_dwell_time:
            sql, params = build_dwell_time_sql(parsed_obj)
            parsed_obj.chart_type = "bar"
        elif parsed_obj.is_stable_avg:
            sql, params = build_stable_avg_sql(parsed_obj)
        else:
            sql, params = build_sql(parsed_obj)

        con = duckdb.connect(str(DB))
        try:
            df = con.execute(sql, params).df()
        finally:
            con.close()

        if df.empty:
            return Response(content=b"No data", media_type="text/plain")

        # ë‹¨ì¼ ê°’ì´ë©´ ê°„ë‹¨ í…ìŠ¤íŠ¸ë¡œ
        if len(df.columns) == 1 and df.columns[0] in ("value", "n"):
            txt = df.to_string(index=False)
            return Response(content=txt.encode("utf-8"), media_type="text/plain; charset=utf-8")

        # ê·¸ë£¹ ê²°ê³¼: xì¶•(ì²«ë²ˆì§¸ ì»¬ëŸ¼), yì¶•(value or n)
        x_col = df.columns[0]
        y_col = "value" if "value" in df.columns else ("n" if "n" in df.columns else df.columns[-1])

        # ğŸ”¥ í•µì‹¬ ë³€ê²½: ë¶„ì„ ìœ í˜• ê¸°ë°˜ ì°¨íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©
        config = get_chart_template(parsed_obj.analysis_type)
        
        # ğŸ”¥ Rule 1: step ê°œìˆ˜ > 12ë©´ â†’ ìš”ì•½ ê·¸ë˜í”„ (group_profileì´ì§€ë§Œ stepì´ ë§ì„ ë•Œ)
        add_others_for_chart = False
        df_all_for_others = None
        if parsed_obj.analysis_type == "group_profile" and parsed_obj.group_by == "step_name" and len(df) > 12:
            # ìš”ì•½ ëª¨ë“œë¡œ ì „í™˜: Top 7 + Others
            if not parsed_obj.top_n:  # ì‚¬ìš©ìê°€ ëª…ì‹œí•˜ì§€ ì•Šì•˜ìœ¼ë©´
                config = get_chart_template("ranking")  # ranking ìŠ¤íƒ€ì¼ë¡œ ì „í™˜
                config["chart_type"] = "horizontal_bar"  # ê°€ë¡œ ë§‰ëŒ€ë¡œ
                parsed_obj.top_n = 7  # Top 7ë§Œ í‘œì‹œ
                add_others_for_chart = True  # Others ì¶”ê°€ í”Œë˜ê·¸
                # ë‚˜ë¨¸ì§€ëŠ” Othersë¡œ ë¬¶ê¸° ìœ„í•´ ì›ë³¸ ì €ì¥ (ê°’ ê¸°ì¤€ ì •ë ¬ í•„ìš”)
                df_all_for_others = df.copy()
                # ê°’ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
                df = df.sort_values(y_col, ascending=False).head(7) if len(df) > 7 else df.sort_values(y_col, ascending=False)
        
        # í…œí”Œë¦¿ ì„¤ì •ì— ë”°ë¼ ë°ì´í„° ì²˜ë¦¬
        if config["use_top_n"] and parsed_obj.top_n and len(df) > parsed_obj.top_n:
            df = df.head(parsed_obj.top_n)
        elif len(df) > 100:
            df = df.head(100)  # ìµœëŒ€ 100ê°œ
        
        # í•œê¸€ ë ˆì´ë¸” ë§¤í•‘
        agg_kr = {"avg": "í‰ê· ", "min": "ìµœì†Œ", "max": "ìµœëŒ€", "count": "ê°œìˆ˜"}.get(parsed_obj.agg, parsed_obj.agg)
        col_kr = parsed_obj.col or "ì „ì²´"
        x_col_kr = "ê³µì • ID" if x_col == "trace_id" else ("ë‹¨ê³„ëª…" if x_col == "step_name" else ("ì¼ì" if x_col == "date" else ("ì‹œê°„" if x_col == "hour" else x_col)))
        y_col_kr = f"{col_kr} {agg_kr}" if parsed_obj.col else agg_kr

        fig, ax = plt.subplots(figsize=(14, 7))
        fig.patch.set_facecolor('white')
        
        # ğŸ”¥ ë¶„ì„ ìœ í˜• ê¸°ë°˜ ê³ ì • í…œí”Œë¦¿ ì ìš©
        if config["chart_type"] == "line" or (parsed_obj.group_by in ("date", "hour", "day") or parsed_obj.date_start or parsed_obj.date_end):
            x_vals = df[x_col].tolist()
            y_vals = df[y_col].astype(float).tolist()
            
            # ë‚ ì§œ/ì‹œê°„ì´ë©´ ì •ë ¬
            if x_col == "date":
                df = df.sort_values("date")
                x_vals = df[x_col].tolist()
                y_vals = df[y_col].astype(float).tolist()
            
            ax.plot(range(len(x_vals)), y_vals, marker='o', linewidth=2, markersize=6, color='#667eea')
            ax.set_xticks(range(len(x_vals)))
            ax.set_xticklabels([str(x) for x in x_vals], rotation=45, ha='right')
            
            # ìµœëŒ€ê°’ í‘œì‹œ
            if y_vals:
                max_idx = y_vals.index(max(y_vals))
                ax.plot(max_idx, y_vals[max_idx], 'ro', markersize=12)
                ax.annotate(f'ìµœëŒ€: {y_vals[max_idx]:.2f}', 
                           xy=(max_idx, y_vals[max_idx]),
                           xytext=(max_idx, y_vals[max_idx] + (max(y_vals) - min(y_vals)) * 0.1),
                           fontsize=10, fontweight='bold',
                           bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),
                           ha='center')
        else:
            # ğŸ”¥ í…œí”Œë¦¿ ì ìš© (analysis_type ê¸°ë°˜)
            # Others ê·¸ë£¹ ì¶”ê°€ (ìš”ì•½ ëª¨ë“œì¼ ë•Œ)
            if add_others_for_chart and df_all_for_others is not None and len(df_all_for_others) > len(df):
                others_df = df_all_for_others.sort_values(y_col, ascending=False).iloc[len(df):]
                others_value_sum = sum(r for r in others_df[y_col].astype(float).tolist())
                others_avg = others_value_sum / len(others_df) if len(others_df) > 0 else 0
                others_row = {x_col: f"Others ({len(others_df)}ê°œ)", y_col: others_avg}
                # DataFrameì— Others í–‰ ì¶”ê°€
                df = pd.concat([df, pd.DataFrame([others_row])], ignore_index=True)
            
            apply_chart_template(ax, df, x_col, y_col, config, parsed_obj)
        
        # ì¶• ë ˆì´ë¸” ë° ì œëª© ì„¤ì •
        title_lines = []
        filter_parts = []  # ì´ˆê¸°í™” í•„ìˆ˜
        
        if parsed_obj.analysis_type == "comparison" and "trace1_avg" in df.columns:
            # ë¹„êµ ì°¨íŠ¸ëŠ” ë³„ë„ ì²˜ë¦¬
            ax.set_xlabel("ë‹¨ê³„ëª…", fontsize=12, fontweight='bold', labelpad=10)
            ax.set_ylabel(f"{col_kr} í‰ê·  (mTorr)", fontsize=12, fontweight='bold', labelpad=10)
            title_lines = [f"{col_kr} í‰ê·  ë¹„êµ (ë‹¨ê³„ëª…ë³„)"]
            if parsed_obj.trace_ids and len(parsed_obj.trace_ids) >= 2:
                title_lines.append(f"ê³µì •: {parsed_obj.trace_ids[0]}, {parsed_obj.trace_ids[1]}")
        else:
            # ì¼ë°˜ ì°¨íŠ¸
            ax.set_xlabel(x_col_kr, fontsize=12, fontweight='bold', labelpad=10)
            ax.set_ylabel(y_col_kr, fontsize=12, fontweight='bold', labelpad=10)
            
            # ì œëª© ìƒì„±
            title_lines.append(f"{y_col_kr} ({x_col_kr}ë³„)")
            
            if parsed_obj.trace_id:
                filter_parts.append(f"ê³µì •: {parsed_obj.trace_id}")
            if len(parsed_obj.trace_ids) > 1 and parsed_obj.analysis_type != "comparison":
                filter_parts.append(f"ê³µì •: {', '.join(parsed_obj.trace_ids)}")
            if parsed_obj.step_name:
                filter_parts.append(f"ë‹¨ê³„: {parsed_obj.step_name}")
            if len(parsed_obj.step_names) > 1:
                filter_parts.append(f"ë‹¨ê³„: {', '.join(parsed_obj.step_names)}")
            if parsed_obj.date_start:
                filter_parts.append(f"ì‹œì‘: {parsed_obj.date_start}")
            if parsed_obj.date_end:
                filter_parts.append(f"ì¢…ë£Œ: {parsed_obj.date_end}")
        
        if filter_parts:
            title_lines.append(" | ".join(filter_parts))
        
        title_text = "\n".join(title_lines)
        ax.set_title(title_text, fontsize=13, fontweight='bold', pad=15, loc='center', wrap=True)
        
        ax.grid(True, alpha=0.3, axis='y', linestyle='--')
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        
        plt.tight_layout(pad=3.0)

        buf = io.BytesIO()
        plt.savefig(buf, format="png", dpi=150, bbox_inches='tight', facecolor='white', pad_inches=0.3)
        plt.close(fig)
        buf.seek(0)
        return Response(content=buf.read(), media_type="image/png")
    except Exception as e:
        # ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë°˜í™˜
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.text(0.5, 0.5, f'Error: {str(e)}', 
                ha='center', va='center', fontsize=14, color='red',
                transform=ax.transAxes)
        ax.axis('off')
        buf = io.BytesIO()
        plt.savefig(buf, format="png", dpi=150, bbox_inches='tight')
        plt.close(fig)
        buf.seek(0)
        return Response(content=buf.read(), media_type="image/png")

# âœ… plotì„ í˜ì´ì§€ë¡œ ë³´ê¸°(ì´ë¯¸ì§€ íƒœê·¸ë¡œ ë Œë”ë§)
@app.get("/plot_page", response_class=HTMLResponse)
def plot_page(request: Request, q: str):
    return templates.TemplateResponse("plot.html", {"request": request, "q": q})

# âœ… ë°ì´í„° íƒìƒ‰: ì»¬ëŸ¼ ëª©ë¡
@app.get("/api/columns")
def get_columns():
    con = duckdb.connect(str(DB))
    df = con.execute("DESCRIBE traces").df()
    # slugifyëœ ì»¬ëŸ¼ëª…ë§Œ (ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë“¤)
    cols = [row[0] for row in df.values if not row[0].startswith('_') and row[0] != 'No.']
    return {"columns": cols}

# âœ… ë°ì´í„° íƒìƒ‰: ê³µì • ID ëª©ë¡
@app.get("/api/traces")
def get_traces():
    con = duckdb.connect(str(DB))
    df = con.execute("SELECT DISTINCT trace_id FROM traces ORDER BY trace_id").df()
    return {"traces": df['trace_id'].tolist()}

# âœ… ë°ì´í„° íƒìƒ‰: ë‹¨ê³„ëª… ëª©ë¡
@app.get("/api/steps")
def get_steps():
    con = duckdb.connect(str(DB))
    df = con.execute("SELECT DISTINCT step_name FROM traces ORDER BY step_name").df()
    return {"steps": df['step_name'].tolist()}

# âœ… ë°ì´í„° íƒìƒ‰: ë°ì´í„° ë²”ìœ„
@app.get("/api/range")
def get_data_range():
    con = duckdb.connect(str(DB))
    min_date = con.execute("SELECT MIN(DATE(timestamp)) as min_date FROM traces").fetchone()[0]
    max_date = con.execute("SELECT MAX(DATE(timestamp)) as max_date FROM traces").fetchone()[0]
    total_rows = con.execute("SELECT COUNT(*) as cnt FROM traces").fetchone()[0]
    return {
        "min_date": str(min_date) if min_date else None,
        "max_date": str(max_date) if max_date else None,
        "total_rows": total_rows
    }

# âœ… CSV ë‹¤ìš´ë¡œë“œ
@app.get("/api/csv")
def download_csv(q: str):
    try:
        parsed_obj = parse_question(q)
        
        # ê³µì • ì¹œí™” ì§€í‘œ ë˜ëŠ” ì´ìƒì¹˜ íƒì§€ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„: trace_compare > overshoot > outlier > ê¸°íƒ€)
        if parsed_obj.is_trace_compare:
            sql, params = build_trace_compare_sql(parsed_obj)
        elif parsed_obj.is_overshoot:
            sql, params = build_overshoot_sql(parsed_obj)
        elif parsed_obj.is_outlier:
            sql, params = build_outlier_detection_sql(parsed_obj)
        elif parsed_obj.is_dwell_time:
            sql, params = build_dwell_time_sql(parsed_obj)
        elif parsed_obj.is_stable_avg:
            sql, params = build_stable_avg_sql(parsed_obj)
        else:
            sql, params = build_sql(parsed_obj)
        
        con = duckdb.connect(str(DB))
        df = con.execute(sql, params).df()
        
        csv_str = df.to_csv(index=False)
        return Response(content=csv_str, media_type="text/csv", 
                       headers={"Content-Disposition": f"attachment; filename=query_result.csv"})
    except Exception as e:
        return {"ok": False, "error": str(e)}

# âœ… íˆìŠ¤í† ë¦¬ ì €ì¥/ì¡°íšŒ (ê°„ë‹¨í•œ JSON íŒŒì¼ ê¸°ë°˜)
HISTORY_FILE = PROJECT_ROOT / "data" / "history.json"

@app.post("/api/history")
def save_history(q: QueryIn):
    try:
        if not HISTORY_FILE.parent.exists():
            HISTORY_FILE.parent.mkdir(parents=True)
        
        history = []
        if HISTORY_FILE.exists():
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                history = json.load(f)
        
        # ì¤‘ë³µ ì œê±° ë° ìµœê·¼ ê²ƒë§Œ ìœ ì§€ (ìµœëŒ€ 100ê°œ)
        history = [h for h in history if h['question'] != q.question]
        history.insert(0, {"question": q.question, "timestamp": datetime.now().isoformat()})
        history = history[:100]
        
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        return {"ok": True}
    except Exception as e:
        return {"ok": False, "error": str(e)}

@app.get("/api/history")
def get_history():
    try:
        if not HISTORY_FILE.exists():
            return {"history": []}
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            history = json.load(f)
        return {"history": history[:20]}  # ìµœê·¼ 20ê°œë§Œ
    except Exception as e:
        return {"ok": False, "error": str(e)}

# âœ… ì¦ê²¨ì°¾ê¸° ì €ì¥/ì¡°íšŒ
FAVORITES_FILE = PROJECT_ROOT / "data" / "favorites.json"

@app.post("/api/favorites")
def save_favorite(q: QueryIn):
    try:
        if not FAVORITES_FILE.parent.exists():
            FAVORITES_FILE.parent.mkdir(parents=True)
        
        favorites = []
        if FAVORITES_FILE.exists():
            with open(FAVORITES_FILE, 'r', encoding='utf-8') as f:
                favorites = json.load(f)
        
        if q.question not in favorites:
            favorites.append(q.question)
        
        with open(FAVORITES_FILE, 'w', encoding='utf-8') as f:
            json.dump(favorites, f, ensure_ascii=False, indent=2)
        
        return {"ok": True}
    except Exception as e:
        return {"ok": False, "error": str(e)}

@app.get("/api/favorites")
def get_favorites():
    try:
        if not FAVORITES_FILE.exists():
            return {"favorites": []}
        with open(FAVORITES_FILE, 'r', encoding='utf-8') as f:
            favorites = json.load(f)
        return {"favorites": favorites}
    except Exception as e:
        return {"ok": False, "error": str(e)}

@app.delete("/api/favorites")
def delete_favorite(q: QueryIn):
    try:
        if not FAVORITES_FILE.exists():
            return {"ok": True}
        
        with open(FAVORITES_FILE, 'r', encoding='utf-8') as f:
            favorites = json.load(f)
        
        favorites = [f for f in favorites if f != q.question]
        
        with open(FAVORITES_FILE, 'w', encoding='utf-8') as f:
            json.dump(favorites, f, ensure_ascii=False, indent=2)
        
        return {"ok": True}
    except Exception as e:
        return {"ok": False, "error": str(e)}
